{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10525 entries, 0 to 10524\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Country          10525 non-null  object\n",
      " 1   News Publisher   10525 non-null  object\n",
      " 2   Country Stance   10525 non-null  object\n",
      " 3   Headline         10525 non-null  object\n",
      " 4   Date             10525 non-null  object\n",
      " 5   Headline Stance  700 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 493.5+ KB\n"
     ]
    }
   ],
   "source": [
    "all_articles = pd.read_csv('./scraped_folders/Cleaned_Articles_manually_labeled.csv')\n",
    "all_articles = all_articles.drop(all_articles.columns[[6,7, 8, 9, 10]], axis=1)\n",
    "all_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Country News Publisher Country Stance  \\\n",
      "0      South Africa           eNCA  Pro Palestine   \n",
      "1      South Africa           eNCA  Pro Palestine   \n",
      "2      South Africa           eNCA  Pro Palestine   \n",
      "3      South Africa           eNCA  Pro Palestine   \n",
      "4      South Africa           eNCA  Pro Palestine   \n",
      "...             ...            ...            ...   \n",
      "10520            US       Fox News     Pro Israel   \n",
      "10521            US       Fox News     Pro Israel   \n",
      "10522            US       Fox News     Pro Israel   \n",
      "10523            US       Fox News     Pro Israel   \n",
      "10524            US       Fox News     Pro Israel   \n",
      "\n",
      "                                                Headline  \\\n",
      "0            Biden announces emergency port for Gaza aid   \n",
      "1      Israel strikes Gaza's Rafah as truce talks und...   \n",
      "2      Gaza hospitals out of fuel, caught in Israel-H...   \n",
      "3      Gazans bury their dead in orchards and footbal...   \n",
      "4      'Exhausted' Gazans desperate for war to end as...   \n",
      "...                                                  ...   \n",
      "10520  Thousands of anti-Israel protesters gathered o...   \n",
      "10521  BBC anchor asks if Israeli forces warned Pales...   \n",
      "10522  Kamala Harris mourns death of Palestinians in ...   \n",
      "10523  Israeli war cabinet minister Benny Gantz quits...   \n",
      "10524  GOP senator calls for Jan 6 style investigatio...   \n",
      "\n",
      "                                      Date Headline Stance parsed_dates  \n",
      "0         Thursday 07 March 2024 - 21:00pm         Neutral   2024-03-07  \n",
      "1      Thursday 22 February 2024 - 13:00pm      Pro-Israel   2024-02-22  \n",
      "2        Monday 13 November 2023 - 05:51am   Pro-Palestine   2023-11-13  \n",
      "3      Thursday 09 November 2023 - 15:55pm   Pro-Palestine   2023-11-09  \n",
      "4      Saturday 30 December 2023 - 05:50am   Pro-Palestine   2023-12-30  \n",
      "...                                    ...             ...          ...  \n",
      "10520                               Jun-09   Pro-Palestine   2024-06-09  \n",
      "10521                               Jun-09   Pro-Palestine   2024-06-09  \n",
      "10522                               Jun-09   Pro-Palestine   2024-06-09  \n",
      "10523                               Jun-09         Neutral   2024-06-09  \n",
      "10524                               Jun-09         Neutral   2024-06-09  \n",
      "\n",
      "[10525 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_and_format_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    if isinstance(date_str, pd.Timestamp):\n",
    "        return date_str.date().strftime('%Y-%m-%d')\n",
    "    if isinstance(date_str, str):\n",
    "        try:\n",
    "            # Attempt to parse with dateutil\n",
    "            parsed_date = parser.parse(date_str, fuzzy_with_tokens=True)\n",
    "            # parsed_date is a tuple where the first element is the datetime object\n",
    "            parsed_datetime = parsed_date[0]\n",
    "            return parsed_datetime.date().strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return date_str\n",
    "\n",
    "all_articles['parsed_dates'] = all_articles['Date'].apply(parse_and_format_date)\n",
    "\n",
    "print(all_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>News Publisher</th>\n",
       "      <th>Country Stance</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline Stance</th>\n",
       "      <th>parsed_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>eNCA</td>\n",
       "      <td>Pro Palestine</td>\n",
       "      <td>Biden announces emergency port for Gaza aid</td>\n",
       "      <td>Thursday 07 March 2024 - 21:00pm</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2024-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>eNCA</td>\n",
       "      <td>Pro Palestine</td>\n",
       "      <td>Israel strikes Gaza's Rafah as truce talks und...</td>\n",
       "      <td>Thursday 22 February 2024 - 13:00pm</td>\n",
       "      <td>Pro-Israel</td>\n",
       "      <td>2024-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>eNCA</td>\n",
       "      <td>Pro Palestine</td>\n",
       "      <td>Gaza hospitals out of fuel, caught in Israel-H...</td>\n",
       "      <td>Monday 13 November 2023 - 05:51am</td>\n",
       "      <td>Pro-Palestine</td>\n",
       "      <td>2023-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>eNCA</td>\n",
       "      <td>Pro Palestine</td>\n",
       "      <td>Gazans bury their dead in orchards and footbal...</td>\n",
       "      <td>Thursday 09 November 2023 - 15:55pm</td>\n",
       "      <td>Pro-Palestine</td>\n",
       "      <td>2023-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>eNCA</td>\n",
       "      <td>Pro Palestine</td>\n",
       "      <td>'Exhausted' Gazans desperate for war to end as...</td>\n",
       "      <td>Saturday 30 December 2023 - 05:50am</td>\n",
       "      <td>Pro-Palestine</td>\n",
       "      <td>2023-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country News Publisher Country Stance  \\\n",
       "0  South Africa           eNCA  Pro Palestine   \n",
       "1  South Africa           eNCA  Pro Palestine   \n",
       "2  South Africa           eNCA  Pro Palestine   \n",
       "3  South Africa           eNCA  Pro Palestine   \n",
       "4  South Africa           eNCA  Pro Palestine   \n",
       "\n",
       "                                            Headline  \\\n",
       "0        Biden announces emergency port for Gaza aid   \n",
       "1  Israel strikes Gaza's Rafah as truce talks und...   \n",
       "2  Gaza hospitals out of fuel, caught in Israel-H...   \n",
       "3  Gazans bury their dead in orchards and footbal...   \n",
       "4  'Exhausted' Gazans desperate for war to end as...   \n",
       "\n",
       "                                  Date Headline Stance parsed_dates  \n",
       "0     Thursday 07 March 2024 - 21:00pm         Neutral   2024-03-07  \n",
       "1  Thursday 22 February 2024 - 13:00pm      Pro-Israel   2024-02-22  \n",
       "2    Monday 13 November 2023 - 05:51am   Pro-Palestine   2023-11-13  \n",
       "3  Thursday 09 November 2023 - 15:55pm   Pro-Palestine   2023-11-09  \n",
       "4  Saturday 30 December 2023 - 05:50am   Pro-Palestine   2023-12-30  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_headline(headline):\n",
    "    parts = headline.split(\"Published\", 1)\n",
    "    return parts[0].strip()\n",
    "\n",
    "all_articles['Headline'] = all_articles['Headline'].apply(clean_headline)\n",
    "all_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10525 entries, 0 to 10524\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Country          10525 non-null  object\n",
      " 1   News Publisher   10525 non-null  object\n",
      " 2   Country Stance   10525 non-null  object\n",
      " 3   Headline         10525 non-null  object\n",
      " 4   Date             10525 non-null  object\n",
      " 5   Headline Stance  700 non-null    object\n",
      " 6   parsed_dates     8261 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 575.7+ KB\n"
     ]
    }
   ],
   "source": [
    "all_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles.to_csv('./scraped_folders/all_articles_cleaned_with_python.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 633 entries, 0 to 10524\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Country          633 non-null    object\n",
      " 1   News Publisher   633 non-null    object\n",
      " 2   Country Stance   633 non-null    object\n",
      " 3   Headline         633 non-null    object\n",
      " 4   Date             633 non-null    object\n",
      " 5   Headline Stance  633 non-null    object\n",
      " 6   parsed_dates     539 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 39.6+ KB\n"
     ]
    }
   ],
   "source": [
    "labeled_data = all_articles.loc[all_articles['Headline Stance'].isin(['Pro-Israel', 'Neutral','Pro-Palestine'])]\n",
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>News Publisher</th>\n",
       "      <th>Country Stance</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Date</th>\n",
       "      <th>parsed_dates</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headline Stance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pro-Israel</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pro-Palestine</th>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>284</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Country  News Publisher  Country Stance  Headline  Date  \\\n",
       "Headline Stance                                                            \n",
       "Neutral              221             221             221       221   221   \n",
       "Pro-Israel           128             128             128       128   128   \n",
       "Pro-Palestine        284             284             284       284   284   \n",
       "\n",
       "                 parsed_dates  \n",
       "Headline Stance                \n",
       "Neutral                   200  \n",
       "Pro-Israel                113  \n",
       "Pro-Palestine             226  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.groupby('Headline Stance').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Neutral       0.66      0.58      0.61        66\n",
      "   Pro-Israel       0.57      0.64      0.60        39\n",
      "Pro-Palestine       0.74      0.76      0.75        85\n",
      "\n",
      "     accuracy                           0.67       190\n",
      "    macro avg       0.65      0.66      0.66       190\n",
      " weighted avg       0.67      0.67      0.67       190\n",
      "\n",
      "Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(labeled_data, test_size=0.30, random_state=42, stratify=labeled_data['Headline Stance'])\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Transform headlines to TF-IDF features\n",
    "X_train = vectorizer.fit_transform(train_data['Headline'])\n",
    "X_test = vectorizer.transform(test_data['Headline'])\n",
    "\n",
    "# Target labels\n",
    "y_train = train_data['Headline Stance']\n",
    "y_test = test_data['Headline Stance']\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm = SVC(kernel='linear',class_weight='balanced')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'Neutral': 0, 'Pro-Israel': 1, 'Pro-Palestine': 2}\n",
    "labeled_data['label'] = labeled_data['Headline Stance'].map(label_mapping)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(labeled_data, test_size=0.2, random_state=42, stratify=labeled_data['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/cwp9b_5j1y9bhnj508m9ntm00000gn/T/ipykernel_44438/3833497662.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_data['label'] = labeled_data['Headline Stance'].map(label_mapping)\n",
      "/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4154274b3e144b2a864642c281bd33c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/506 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a23b16da52a45c2896e377ab16e9b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/127 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64   int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/lib/python3.11/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84fb5371e5b4ad7b3f06aea3e5c6781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1102, 'learning_rate': 1.9375e-05, 'epoch': 0.16}\n",
      "{'loss': 1.1711, 'learning_rate': 1.8750000000000002e-05, 'epoch': 0.31}\n",
      "{'loss': 1.0813, 'learning_rate': 1.8125e-05, 'epoch': 0.47}\n",
      "{'loss': 1.08, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.62}\n",
      "{'loss': 1.0974, 'learning_rate': 1.6875e-05, 'epoch': 0.78}\n",
      "{'loss': 1.0171, 'learning_rate': 1.6250000000000002e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8829d316b6654ee793e44ee2b96ba322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.036670207977295, 'eval_runtime': 3.6868, 'eval_samples_per_second': 34.447, 'eval_steps_per_second': 4.34, 'epoch': 1.0}\n",
      "{'loss': 1.1111, 'learning_rate': 1.5625e-05, 'epoch': 1.09}\n",
      "{'loss': 1.0572, 'learning_rate': 1.5000000000000002e-05, 'epoch': 1.25}\n",
      "{'loss': 1.106, 'learning_rate': 1.4375e-05, 'epoch': 1.41}\n",
      "{'loss': 1.0831, 'learning_rate': 1.375e-05, 'epoch': 1.56}\n",
      "{'loss': 1.0463, 'learning_rate': 1.3125e-05, 'epoch': 1.72}\n",
      "{'loss': 0.9777, 'learning_rate': 1.25e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319c3dd33dca41b09a41d5e139a5e1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0552150011062622, 'eval_runtime': 3.6099, 'eval_samples_per_second': 35.181, 'eval_steps_per_second': 4.432, 'epoch': 2.0}\n",
      "{'loss': 0.9976, 'learning_rate': 1.1875e-05, 'epoch': 2.03}\n",
      "{'loss': 1.0235, 'learning_rate': 1.125e-05, 'epoch': 2.19}\n",
      "{'loss': 0.9647, 'learning_rate': 1.0625e-05, 'epoch': 2.34}\n",
      "{'loss': 1.0337, 'learning_rate': 1e-05, 'epoch': 2.5}\n",
      "{'loss': 0.9756, 'learning_rate': 9.375000000000001e-06, 'epoch': 2.66}\n",
      "{'loss': 0.9724, 'learning_rate': 8.750000000000001e-06, 'epoch': 2.81}\n",
      "{'loss': 0.9356, 'learning_rate': 8.125000000000001e-06, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13bb3f623b3497ea77f09f1c1fd97c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9715608954429626, 'eval_runtime': 11.7322, 'eval_samples_per_second': 10.825, 'eval_steps_per_second': 1.364, 'epoch': 3.0}\n",
      "{'loss': 0.905, 'learning_rate': 7.500000000000001e-06, 'epoch': 3.12}\n",
      "{'loss': 0.8745, 'learning_rate': 6.875e-06, 'epoch': 3.28}\n",
      "{'loss': 0.8394, 'learning_rate': 6.25e-06, 'epoch': 3.44}\n",
      "{'loss': 0.7859, 'learning_rate': 5.625e-06, 'epoch': 3.59}\n",
      "{'loss': 0.8276, 'learning_rate': 5e-06, 'epoch': 3.75}\n",
      "{'loss': 0.7996, 'learning_rate': 4.3750000000000005e-06, 'epoch': 3.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d402951ff83649478e7a71f3bbc9491a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9467660784721375, 'eval_runtime': 6.2842, 'eval_samples_per_second': 20.209, 'eval_steps_per_second': 2.546, 'epoch': 4.0}\n",
      "{'loss': 0.8421, 'learning_rate': 3.7500000000000005e-06, 'epoch': 4.06}\n",
      "{'loss': 0.6652, 'learning_rate': 3.125e-06, 'epoch': 4.22}\n",
      "{'loss': 0.695, 'learning_rate': 2.5e-06, 'epoch': 4.38}\n",
      "{'loss': 0.7793, 'learning_rate': 1.8750000000000003e-06, 'epoch': 4.53}\n",
      "{'loss': 0.622, 'learning_rate': 1.25e-06, 'epoch': 4.69}\n",
      "{'loss': 0.6139, 'learning_rate': 6.25e-07, 'epoch': 4.84}\n",
      "{'loss': 0.7269, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5c27113e114866bb1c556c0408cea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9287413358688354, 'eval_runtime': 5.7821, 'eval_samples_per_second': 21.964, 'eval_steps_per_second': 2.767, 'epoch': 5.0}\n",
      "{'train_runtime': 437.2754, 'train_samples_per_second': 5.786, 'train_steps_per_second': 0.732, 'train_loss': 0.931811572611332, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f321513488cf4ca5859b8ef690af8b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.9287413358688354, 'eval_runtime': 4.3847, 'eval_samples_per_second': 28.964, 'eval_steps_per_second': 3.649, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3424e6154f149fd8e418c2282c32d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558013a06ced4941ac817eed785c0588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57        44\n",
      "           1       0.47      0.31      0.37        26\n",
      "           2       0.56      0.75      0.64        57\n",
      "\n",
      "    accuracy                           0.57       127\n",
      "   macro avg       0.57      0.52      0.53       127\n",
      "weighted avg       0.58      0.57      0.56       127\n",
      "\n",
      "Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "#XLNet\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# Ensure the labels are consistent\n",
    "label_mapping = {'Neutral': 0, 'Pro-Israel': 1, 'Pro-Palestine': 2}\n",
    "labeled_data['label'] = labeled_data['Headline Stance'].map(label_mapping)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(labeled_data, test_size=0.2, random_state=42, stratify=labeled_data['label'])\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Headline'], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(train_data['label'].dtype, \" \",test_data['label'].dtype)\n",
    "# Load the model\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=3)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "\n",
    "# Predict on test data\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(axis=1)\n",
    "\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = predictions.predictions.argmax(axis=1)\n",
    "\n",
    "# Evaluate and print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_data['label'], pred_labels))\n",
    "print(f\"Accuracy: {accuracy_score(test_data['label'], pred_labels):.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.45      0.40        44\n",
      "           1       0.19      0.50      0.28        26\n",
      "           2       0.33      0.02      0.03        57\n",
      "\n",
      "    accuracy                           0.27       127\n",
      "   macro avg       0.29      0.32      0.24       127\n",
      "weighted avg       0.31      0.27      0.21       127\n",
      "\n",
      "Accuracy: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/shivam/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "/var/folders/f6/cwp9b_5j1y9bhnj508m9ntm00000gn/T/ipykernel_58218/2325467181.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_data['label'] = labeled_data['Headline Stance'].map(label_mapping)\n",
      "/var/folders/f6/cwp9b_5j1y9bhnj508m9ntm00000gn/T/ipykernel_58218/2325467181.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labeled_data['compound_score'] = labeled_data['Headline'].apply(analyze_sentiment)\n"
     ]
    }
   ],
   "source": [
    "#VADER with logistic regression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to apply VADER sentiment analysis and return compound score\n",
    "def analyze_sentiment(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "# Apply sentiment analysis to each headline\n",
    "label_mapping = {'Neutral': 0, 'Pro-Israel': 1, 'Pro-Palestine': 2}\n",
    "labeled_data['label'] = labeled_data['Headline Stance'].map(label_mapping)\n",
    "\n",
    "labeled_data['compound_score'] = labeled_data['Headline'].apply(analyze_sentiment)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(labeled_data, test_size=0.20, random_state=42, stratify=labeled_data['label'])\n",
    "\n",
    "# Define features and labels\n",
    "X_train = train_data[['compound_score']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['compound_score']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42,class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Neutral       1.00      0.04      0.07        56\n",
      "   Pro-Israel       0.45      0.16      0.23        32\n",
      "Pro-Palestine       0.46      0.94      0.62        71\n",
      "\n",
      "     accuracy                           0.47       159\n",
      "    macro avg       0.64      0.38      0.31       159\n",
      " weighted avg       0.65      0.47      0.35       159\n",
      "\n",
      "Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Example dataset with labeled headlines\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(labeled_data, test_size=0.25, random_state=42, stratify=labeled_data['Headline Stance'])\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Transform headlines to TF-IDF features\n",
    "X_train = vectorizer.fit_transform(train_data['Headline'])\n",
    "X_test = vectorizer.transform(test_data['Headline'])\n",
    "\n",
    "# Target labels\n",
    "y_train = train_data['Headline Stance']\n",
    "y_test = test_data['Headline Stance']\n",
    "class_counts = y_train.value_counts()\n",
    "class_weights = {cls: np.sum(class_counts) / (len(class_counts) * count) for cls, count in class_counts.items()}\n",
    "# Initialize and train the Naive Bayes classifier (MultinomialNB)\n",
    "nb = MultinomialNB(class_prior=list(class_weights.values()))\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/cwp9b_5j1y9bhnj508m9ntm00000gn/T/ipykernel_58218/3760064022.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  svm_label['Headline Stance'] = y_pred_new\n"
     ]
    }
   ],
   "source": [
    "svm_label = all_articles[['Country','News Publisher','Country Stance','Headline','parsed_dates']]\n",
    "\n",
    "# Transform new headlines to TF-IDF features\n",
    "X_new = vectorizer.transform(svm_label['Headline'])\n",
    "\n",
    "# Predict using the SVM classifier\n",
    "y_pred_new = svm.predict(X_new)\n",
    "svm_label['Headline Stance'] = y_pred_new\n",
    "svm_label.to_csv('./scraped_folders/all_articles_svm_labeled.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Country News Publisher Headline Stance  Count\n",
      "0        Ireland  Breaking News         Neutral    311\n",
      "1        Ireland  Breaking News      Pro-Israel    225\n",
      "2        Ireland  Breaking News   Pro-Palestine    471\n",
      "3        Ireland    The Journal         Neutral    129\n",
      "4        Ireland    The Journal      Pro-Israel     87\n",
      "5        Ireland    The Journal   Pro-Palestine    230\n",
      "6   South Africa           SABC         Neutral    208\n",
      "7   South Africa           SABC      Pro-Israel     63\n",
      "8   South Africa           SABC   Pro-Palestine    265\n",
      "9   South Africa           eNCA         Neutral    118\n",
      "10  South Africa           eNCA      Pro-Israel     67\n",
      "11  South Africa           eNCA   Pro-Palestine    202\n",
      "12            UK            BBC         Neutral    200\n",
      "13            UK            BBC      Pro-Israel    153\n",
      "14            UK            BBC   Pro-Palestine    296\n",
      "15            UK   The Guardian         Neutral    766\n",
      "16            UK   The Guardian      Pro-Israel    398\n",
      "17            UK   The Guardian   Pro-Palestine   1100\n",
      "18            US            CNN         Neutral   1969\n",
      "19            US            CNN      Pro-Israel   1062\n",
      "20            US            CNN   Pro-Palestine   1735\n",
      "21            US       Fox News         Neutral    194\n",
      "22            US       Fox News      Pro-Israel    158\n",
      "23            US       Fox News   Pro-Palestine    118\n"
     ]
    }
   ],
   "source": [
    "stance_counts = svm_label.groupby(['Country','News Publisher', 'Headline Stance']).size().reset_index(name='Count')\n",
    "print(stance_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
